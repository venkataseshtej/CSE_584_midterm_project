# CSE-584 Midterm Project: LLM Classifier

## Project Overview

This repository contains the code and resources for the midterm project in CSE-584: Machine Learning. The goal of this project is to classify the outputs (completions) of different large language models (LLMs) based on a dataset of truncated text inputs. The models used in this study are:

- **BERT**
- **DistilGPT-2**
- **Flan-T5**
- **GPT-Neo**
- **OPT**

A BERT-based classifier is trained to predict which LLM generated the completion for a given input sentence. Hyperparameter tuning was performed using Optuna, and the model's performance is evaluated using accuracy, F1-score, and confusion matrices.

## Project Files

The repository contains the following files:

- **data.csv**: The dataset with the original text inputs (xi only).
- **output_check_parallel_3500_final.csv**: A CSV file containing 17500 examples of text inputs(xi) and completions(xj) generated by various LLMs, used for training and validating the classifier. You can also generate this file after running xj_generation_and_classifier.ipynb file with 3500*5 notebook cell. There are clear subheadings in the notebook.
- **output_check_parallel_750_final.csv**: A CSV file containing 750 examples of text inputs(xi) and completions(xj) used for testing. This also can be generated after running test data generation cell (last cell ) in xj_generation_and_classifier.ipynb notebook.
- **testing_confusion_matrix.ipynb**: Jupyter Notebook used for testing the classifier and plotting the confusion matrix.
- **xj_generation_and_classifier.ipynb**: The main Jupyter Notebook used for generating completions and training the BERT-based classifier.
- **Loss.png**: A plot showing the training and validation accuracy and loss over the epochs.
- **confusion_matrix.png**: A confusion matrix visualizing the classifier's performance on the test data.

NOTE: https://drive.google.com/file/d/1mhr-DUqF4RqHAhVN5GYprUyjzyARTnwM/view?usp=drive_link

The above is the link for .pth file of saved model after training and validation. You can use this file as input for testing_confusion_matrix.ipynb for generating the confusion matrix. Alterantively you can also generate the .pth file after running the xj_generation_and_classifier.ipynb with the updated hyper-parameters cell in notebook.

## Setup Instructions

### 1. Clone the Repository 

Clone the repository to your local machine and run the notebooks in google collab / local:


https://github.com/venkataseshtej/CSE_584_midterm_project/tree/main

### 2. Install Dependencies
Every required installation is already given in the notebook cells. Please run these dependency cells which are at the start of the these notebooks.

Alteratively you can also do the below:

The project uses the following Python libraries:

transformers
torch
pandas
optuna
matplotlib
sklearn
You can install them using pip:

pip install transformers 
pip install optuna 

### 3. Running the Code
You can open the Jupyter notebooks to view or run the code interactively:

xj_generation_and_classifier.ipynb: This notebook contains the code for generating completions using different LLMs and training the BERT-based classifier.
NOTE: You need not run the entire notebook cells as it has several experimentations (which are clearly described as headings in the cells). You can run the cells that is generating 3500 * 5 texts (xj) and the final classifier cell by BERT after getting the hyper-parameters to get the end results. I have also included every input and outputs in this repo. 

testing_confusion_matrix.ipynb: This notebook evaluates the model and generates a confusion matrix based on the unseen test data which is also provided. This notebook can be easily running on google-collab. The inputs and outputs with same names are already provided in this repo.

To run the notebooks, use:
bash
Copy code
jupyter notebook
Open the respective notebook files from the Jupyter dashboard.

### 4. Results
The classifier achieved the following performance:

Training Accuracy: 96.7% after 4 epochs (Used Early stopping with patience 2).
Validation Accuracy: 89.5%
Test Accuracy: 89% on a randomly selected test set of 700 samples

### 5. Visualizations
Training and Validation Curves: Available in Loss.png, showing the training and validation loss and accuracy across epochs.
Confusion Matrix: Available in confusion_matrix.png, visualizing the classifier's performance across the five LLMs.

### 6. Hyperparameter Tuning
Hyperparameter tuning was conducted using Optuna, and the best hyperparameters found are:

Learning Rate: 2.7305e-5
Dropout Rate: 0.31044018940585527
Batch Size: 32
These values were used to achieve the best results during training and validation.

### 7.Future Work
Potential future work could explore additional models, multi-task learning, and incorporating multi-modal inputs to improve the classification performance.
